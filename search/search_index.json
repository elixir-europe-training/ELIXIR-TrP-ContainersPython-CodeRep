{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#containers-achieving-portability-reproducibility-of-research-computational-environments-python-stream","title":"Containers: Achieving Portability &amp; Reproducibility of Research Computational Environments (python stream)","text":""},{"location":"#authors","title":"Authors","text":"<p>Pen-Yuan Hsing</p> <p>  University of Bristol, United Kingdom. </p> <p>Alexander Botzki</p> <p> :simple-linkedin: Alexander Botzki, VIB Technology Training, VIB, Belgium </p> <p>Mark Fernandes</p> <p> :simple-linkedin: Mark Fernandes, Teaching Associate, Bioinformatics Training Facility, Dept. of Genetics, University of Cambridge </p> <p>Naeem Muhammad</p> <p> :simple-linkedin: Naeem Muhammad, Research Data Manager, Research Coordination Office, KU Leuven, Belgium. </p>"},{"location":"#lesson-overview","title":"Lesson overview","text":"<p> Description  This course explores several different approaches to provide an end user with a software environment that ensures successful execution of       scientific analysis software in a reproducible manner. It then focuses upon an examplar - Software Containers (Specifically implemented         using Docker). </p> <p></p> <p> Prerequisites To be able to follow this course, learners should have knowledge in:  </p> <ol> <li>Familiarity with using a text editor to create and edit plain ASCII text files.   </li> <li>Basic experience in using command-line Linux.   </li> <li>Additionally, students will find it beneficial to have an overview of how software is installed under Linux.   </li> </ol> <p> Learning Outcomes: By the end of the course, learners will be able to:  </p> <ol> <li>State several approaches to reproducible software environments and critically debate the strengths and weaknesses of each approach.    </li> <li>Identify the roles of particular commands in a Dockerfile and create simple functional Docker containers.     </li> </ol> <p></p> <p> Target Audience: Researchers, undergraduate students, postgraduate students, etc\u2026 </p> <p> Level: Beginner/Intermediate  </p> <p> License: Creative Commons Attribution 4.0 International License </p> <p> Funding: This project has received funding from [name of funders].  </p>"},{"location":"#contributors","title":"Contributors","text":"<p>Christof De Bo</p> <p>  Christof De Bo, VIB Technologies, VIB, Belgium </p>"},{"location":"#citing-this-lesson","title":"Citing this lesson","text":"<p>Please cite as:</p> <ol> <li>Mark Fernandes, Pen-Yuan Hsing, Naeem Muhammad, Alexander Botzki. (2024). The ELIXIR Code Reproducibility lesson - Software Containers for computational reproducibility. Zenodo DOI: {here}</li> <li>Geert van Geest, Elin Kronander, Jose Alejandro Romero Herrera, Nadja \u017dlender, &amp; Alexia Cardona. (2023). The ELIXIR Training Lesson Template - Developing Training Together (v1.0.0-alpha). Zenodo. https://doi.org/10.5281/zenodo.7913092. </li> </ol>"},{"location":"#setup","title":"Setup","text":""},{"location":"#data-setup","title":"Data setup","text":"<p>To run this lesson you need to install code and data from here</p>"},{"location":"#software-setup","title":"Software setup","text":"<p>To run this course you need to install Docker on your computer Instructions here and have access to a text editor program that can edit and save ASCII text documents (Not a word processor like Word).  NB Course examples assume an Intel architecture computer (i386). The author has ssucessfully run the exercises on an Apple Silicon Macintosh  by creating a UTM Debian linux Virtual machine with Intel emulation.   </p> <p>Blank Sillouette from User Icon Vectors by Vecteezy</p>"},{"location":"course_schedule/","title":"Course schedule","text":"start end topic 10:00 10:30 coffee! 12:00 13:00 lunch! <p>Generate markdown tables at tablesgenerator.com</p>"},{"location":"follow_up_training/","title":"Follow up training","text":"<p>The CodeRep (Code Reproducibility) project  is intended to provide training resources on all aspects of reproducible coding. There will be tracks for R &amp; Python programmers.      </p> <ul> <li>Literate Programming   </li> <li>Version Control   </li> <li>Documentation   </li> <li>Continuous Integration &amp; Development (CI/CD)   </li> <li>Testing  </li> <li>Deployment (Containers)  </li> </ul>"},{"location":"chapters/chapter_01/","title":"1. The Rocky Road to Reproducibility","text":"Rocky Road Brownies by Chocolate-Dessert-Recipes.com, CC BY 2.0 <p>Teaching Outcomes</p> <p>By the end of this lesson, you will be able to</p> <ul> <li>List the issues relating to running software on users machines</li> <li>Students can name the benefits and drawbacks of native installations, virtual machines (VMs) and containers</li> </ul> <p>Teaching Experience(s) This course will delivered by a mixture of the following:    </p> <ul> <li>Lectures</li> <li>short quizzes</li> <li>Open class discussions</li> </ul>"},{"location":"chapters/chapter_01/#enabling-use-of-your-software-by-other-researchers","title":"Enabling use of your software by other researchers","text":"<p>So far we have learnt how to program, how to document our code, how to test it and how to publish it to a repository (Findable &amp; Accessible under the FAIR principles) - what more do we have to do?</p>"},{"location":"chapters/chapter_01/#well-it-works-on-my-machine-how-often-do-we-hear-that","title":"\u201cWell it works on my machine\u2026\u201d How often do we hear that?","text":"<p>Why is it so difficult to run other peoples\u2019 code?</p> <p>This is a fair question - over your career there will be many times you will come across software that is potentially useful to you, that you download &amp; install and find that it doesn\u2019t work (maybe with a cryptic error message for you to search for online).</p> <p>Potential barriers</p> <ul> <li>Their computer has different hardware or operating system to yours. Executable code is often created to run on a specific microprocessor hardware. MS-Windows programs run on ia-x86 processors (and possibly ARM ones) whilst MacOS has run on 68K, PowerPC, Ia86 and ARM (M1&amp;M2). The main target Operating systems are Windows, MacOS &amp; Linux - all of which have different interactions with hardware and applications. In theory this can be catered for by developing versions for the different hardware and OS platforms nut this can be expensive in time, equipment, and support resources.</li> <li>Different Software versions</li> <li>Users\u2019 Technical ability \u2013 It\u2019s wrong to assume high IT experience or to expect them to attain it just to use your software (Raising the \u2018cost of entry\u2019 and dissuading them from using it).</li> </ul> <p></p>A Summary of the Pros &amp; Cons of providing detailed DIY instructions Pros Cons Closest to the software authors\u2019 development environment Not always easy to capture exact pre-requisites Can require significant IT experience or support if issues are encountered Could override/replace version of existing software on users PC <p>Challenge:</p> <p>In teams analyse the example R or Python programs with respect to potential barriers to usage by others. We will then have a class discussion of the potential issues you have identified</p> <p>So, what can we do about this?</p> <ul> <li>Extensive documentation on installing all the pre-requisites to run our software including specific version numbers. Note versions are prone to change and so we would have to keep this \u2018recipe\u2019 up to date to ensure continued success.</li> <li>Include Virtual environments in the instructions</li> <li>Create a Virtual Machine (VM)</li> <li>Create a software Container e.g. a Docker container.</li> </ul>"},{"location":"chapters/chapter_01/#what-is-a-virtual-environment","title":"What is a virtual environment?","text":"<p>A virtual environment is a tool that lets you create an isolated tailored environment for a particular application. It enables you to have different versions of the same tools/packages or languages on the same machine by partitioning the environment. Basically when you switch to (activate) an environment then you only have access to the tools that you installed in that environment.    </p> <p>With Python we have an embarrassment of riches when it comes to virtual environment tools. It comes with the venv tool but many others are available (conda, virtualenv and poetry to name but a few). Each comes with its own advantages, disadvantages  and features.   </p> <p>Which one do I use?</p> <p>That is a very good question and the answer is \u201cIt depends\u2026\u201d  Reasons to use venv: - On Python 3.3 or later versions  - Don\u2019t want install any more software (venv is usually \u2018baked\u2019 into a python installation  whereas virtualenv has to be installed (e.g. \u2018pip install \u2013user virtualenv\u2019 ) i.e. likely  to be on an application end-users python installation.  - Wanting only a simple, lightweight and easy-to-use tool - Need the pip built-in support   Reasons to use virtualenv:\u2028  - You are stuck on an older version of Python (pre-3.3)  - Require virtual environements using specific versions of the Python interpreter  - Need more control over the virtual environment setup than supplied by venv      </p> <p>How do we use a virtual environment? (An example using venv) </p> <ol> <li> <p>Create the virtual environment  <code>python -m venv &lt;directory&gt;</code>     This creates the VE directory (if it doesn\u2019t exist already) along with symbolic links to the default version of    the python interpreter (can be over-ridden to use other versions) along with directories to store the VE-specific    installed packages and scripts to activate &amp; deactivate the environment.    </p> </li> <li> <p>Move into the environments directory and activate it  <code>cd &lt;directory&gt;</code> <code>source bin/activate</code> Notice how the command prompt now starts with the environment name. </p> </li> <li> <p>Install whatever packages you need using the pip Python package manager (e.g. with \u2018pip install -r requirements.txt\u2019).   <code>python -m pip install &lt;package&gt;</code> or <code>python -m pip install &lt;package&gt;==&lt;version&gt;</code> To install a particular version of a package</p> </li> <li> <p>Copy in/Download your source code and any required data   <code>cp &lt;source location&gt;/&lt;application.py&gt; &lt;application.py&gt;</code> </p> </li> <li> <p>Run the application   <code>python &lt;application.py&gt;</code> </p> </li> <li> <p>Deactivate the environment to return you to your default Python environment and packages e.g. to run your \u2018normal\u2019 software.     <code>deactivate</code> Notice how the command prompt has reverted to it\u2019s previous form </p> </li> </ol> <p>Those commands don\u2019t work on my nachine!</p> <p>Weren\u2019t we supposed to be getting away from that sort of thing?  Unfortunately, depending upon your Operating System and how it is setup/python is  installed you many have to use \u2018python3\u2019 or \u2018pip3\u2019 in place of python or pip.    You shoul make sure that your installed python is version 3.x as version 2 is no  longer supported (Type \u2018python \u2013version\u2019 to find out wehat you have).   </p>"},{"location":"chapters/chapter_01/#operating-system-variations-mainly-windows","title":"Operating System variations (Mainly Windows)","text":"Command Linux Windows MacOS Create VE python -m venv  python -m venv  python -m venv  Activate VE source bin/activate Scripts\\activate.bat or Scripts\\Activate.ps1 (Powershell) source bin/activate Deactvate VE deactivate deactivate deactivate <p>One complication is that you have to emember to \u2018activate\u2019 the specific environment for the selected application to have the correct supporting software infrastructure. That said there are (several) additional tools that activate the virtual environment when you move (cd) into the programs subdirectory an example of this sort of tool is direnv. The downside to this is that you need to choose the tool appropriate/best suited for your application and provide instructions for theend-user to install it (who may have other similar &amp; potentially incompatible tools installed,).   </p> <p>Virtual environment exercise</p> <ul> <li>Use pip to install version 2.2.26 of django web framework package</li> <li>Create a directory with a virtual environment using \u2018venv\u2019</li> <li>in the environment, install version 4.0.3 of django</li> <li>Turn the VE on and off and demonstrate that two different django environments are available.    </li> </ul> Solution (linux) <p><code>python -m pip install django==2.2.26</code> <code>python -m pip list</code> <code>python -m venv env_exercise</code> <code>cd env_exercise</code> <code>source bin/activate</code> <code>python -m pip install django==4.0.3</code> <code>python -m pip list</code> <code>deactivate</code> <code>python -m pip list</code> </p> <p></p>A Summary of the Pros &amp; Cons of using virtual environments Pros Cons Lots of options to choose from Lots of options to choose from Application environment does not affect users other programs Need to know how to use useful when developing (can create requirements.txt e.g. python -m pip freeze &gt; requirements.txt) Must remember to activate/deactivate - Extra resource usage memory &amp; diskspace for python version &amp; packages - use of more sopisticated environments e.g. virtualenv need installation"},{"location":"chapters/chapter_01/#what-is-a-virtual-machine","title":"What is a virtual machine?","text":"<p>Stated simply a virtual machine (VM) is software that emulates the hardware and software of a computer and runs this emulation on your (host) computer. A layer, called the hypervisor, has the role of running the VM and transferring data in and out of it. </p> .   <ul> <li>Examples of software to host VMs: Microsoft Hyper-V, Virtualbox (Mac OS, Windows &amp; Linux) UTM (recommended for Apple Silicon e.g. M2 Macs).  </li> </ul> <p></p>A Summary of the Pros &amp; Cons of using Virtual Machines Pros Cons Does not affect Host OS Can require a similar level of IT knowledge/expertise to create the software environment for VM Can run several servers on one machine Each VM simulates the client OS as well as the hardware so they can get large and heavily consume disk &amp; memory resources and can be slow to start up Simulates hardware resources that may not be present on host hardware"},{"location":"chapters/chapter_01/#what-is-a-container","title":"What is a container?","text":"<p>Let\u2019s consider the analogy of shipping containers that are used throughout the world.</p> <p>. </p> <p>Photo by\u00a0Nur Alamin\u00a0on\u00a0Unsplash</p> <p>. </p> <p>Photo by\u00a0Ian Taylor\u00a0on\u00a0Unsplash</p> <p>. </p> <p>Photo by\u00a0Michael SKOPAL\u00a0on\u00a0Unsplash</p> <p>. </p> <p>Photo by\u00a0Nathan Cima\u00a0on\u00a0Unsplash</p> <p>Real-world containers are:</p> <ul> <li>Standardised size/shape/Dimensions</li> <li>Stackable design</li> <li>Carried by a variety of means of transportation</li> <li>Standardised machinery to load &amp; unload containers</li> </ul> <p>A software container is defined by a manifest or recipe file that lists all of the software and files to be installed within it but makes use of functions from the Host OS,</p> <ul> <li>Can be executed on Windows, MacOS &amp; Linux</li> <li>Standardised recipe for building and loading/running a container for all supported platforms</li> <li>Multiple containers can be run on a host operating system  .   A Summary of the Pros &amp; Cons of using Software Containers </li> </ul> Pros Cons Does not affect software installations on host computer i.e. install into tabula rasa environment. Requires expertise training in creating the Dockerfiles Lightweight - consumes less resources on host computer and faster to launch than VMs Should do tests to compare results with native install Uses Dockerfiles to script construction of compute environment Supported/welcomed by most Cloud computing providers. Many click &amp; launch options (including Gitpod) are available. <p>We will cover creating a Dockerfile later in this course.</p> <p>Introduction comprehension exercise 1</p> <p>Your computer runs python 3.1 and you do not want to upgrade it. You need virtual environments for a   project and wish to use version 3.0 for your project. You should install virtualenv - TRUE or FALSE?</p> answer <p>TRUE    </p> <p>Introduction comprehension exercise 2</p> <p>Your software project will access a CD/DVD-ROM drive image containing data but you cannot guarantee    that the end-user has this hardware on their computer. This cannot be solved by deploying a virtual   machine - TRUE or FALSE?</p> answer <p>FALSE A VM can emulate hardware e.g. a CD-ROM drive as well as software</p>"},{"location":"chapters/chapter_02/","title":"2. The Docker Dance","text":""},{"location":"chapters/chapter_02/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>fetch and run Docker containers on their computer.</li> <li>interpret the instructions of a Dockerfile</li> <li>create simple Docker containers to run simple python/R scripts.</li> </ul>"},{"location":"chapters/chapter_02/#material","title":"Material","text":"<p> Show the presentation</p> <ul> <li>Unix command line E-utilities documentation</li> </ul>"},{"location":"chapters/chapter_02/#21-docker-dance-creating-containers-using-docker","title":"2.1 Docker Dance (Creating containers using Docker)","text":"<p>We will use Docker as an example to illustrate the development and use of containers.</p>"},{"location":"chapters/chapter_02/#install-docker","title":"Install Docker","text":"<p>Please follow the installation of the latest version of Docker Desktop for your operating system. It is described at Get Docker</p> <p>Info</p> <p>Commercial use of Docker Desktop in larger enterprises (more than 250 employees OR more than $10 million USD in annual revenue) requires a paid subscription. Note that \u2018commercial use\u2019 is interpreted quite broad. </p>"},{"location":"chapters/chapter_02/#introducing-the-dockerfile","title":"Introducing the Dockerfile","text":"<p>The Dockerfile is the starting point of the Docker Dance which is schematically drawn here.</p> <p></p> <p>Now, let\u2019s focus on the instructions for building Docker container images which are saved in a text file, named by default Dockerfile.</p> <p>This is a basic recipe with three statements, one FROM and two RUN statements. </p> <p>To follow along on your own, copy the content of the shown <code>Dockerfile</code> into a file named <code>Dockerfile</code> and save the file on your disk.</p> Dockerfile<pre><code>FROM ubuntu:18.04\n\nRUN apt update &amp;&amp; apt -y upgrade\nRUN apt install -y wget\n</code></pre> <p>The FROM statement describes the parent image. Typically, an \u2018operating\u2019 system but you can also use an image of other parties as a starting point. This instruction creates the base layer.</p> <pre><code>FROM ubuntu:18.04\n</code></pre> <p>Recommendation</p> <p>Pin the version of the OS of the base layer. There is an interesting publication regarding recommendation when manually crafting Dockerfiles. Rule 5 points out the importance of pinning versions of the base image but also system libraries or other installed software. </p> <p>The RUN statement specifies the command to execute inside the image filesystem.</p> <p>Think about it this way: every RUN line is essentially what you would run to install programs on a freshly installed Ubuntu OS. This command will be executed as root in the container.</p> <pre><code>RUN apt install wget\n</code></pre> <p>Each row in the recipe corresponds to a layer of the final image. </p>"},{"location":"chapters/chapter_02/#anatomy-of-the-commands","title":"Anatomy of the commands","text":"<p>With this basic Dockerfile, we will already start the build process which creates an image. For reference, have a look at the sketch of the Docker Dance above.</p> <p>Building Docker image</p> <p>The build command implicitly looks for a file named <code>Dockerfile</code> in the current directory:</p> <pre><code>docker build .\n\n# or by specifying the exact file name\n\ndocker build --file Dockerfile .\n</code></pre> <p>Syntax: -file / -f</p> <p>. stands for the context (in this case, current directory) of the build process. This makes sense if during the build process, we will copy files from local filesystem, for instance. </p> <p>Info</p> <p>Avoid contexts (directories) overpopulated with files (even if not actually used in the recipe).</p> <p>You can define a specific name for the image during the build process.</p> <p>Syntax: -t imagename:tag. If not defined :tag default is latest.</p> <p>Exercise</p> <pre><code>docker build -t mytestimage:v1 .\n</code></pre> <p>The following output should be shown:</p> <pre><code>account@your-computer folder % docker build -f Dockerfile .\n[+] Building 11.3s (7/7) FINISHED                                                                                                                                                                                               docker:desktop-linux\n =&gt; [internal] load build definition from Dockerfile                                                                                                                                                                                            0.0s\n =&gt; =&gt; transferring dockerfile: 113B                                                                                                                                                                                                            0.0s\n =&gt; [internal] load .dockerignore                                                                                                                                                                                                               0.0s\n =&gt; =&gt; transferring context: 2B                                                                                                                                                                                                                 0.0s\n =&gt; [internal] load metadata for docker.io/library/ubuntu:18.04                                                                                                                                                                                 1.6s\n =&gt; [1/3] FROM docker.io/library/ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98                                                                                                                           3.4s\n =&gt; =&gt; resolve docker.io/library/ubuntu:18.04@sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98                                                                                                                           0.0s\n =&gt; =&gt; sha256:064a9bb4736de1b2446f528e4eb37335378392cf9b95043d3e9970e253861702 22.71MB / 22.71MB                                                                                                                                                2.6s\n =&gt; =&gt; sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98 1.33kB / 1.33kB                                                                                                                                                  0.0s\n =&gt; =&gt; sha256:f97a5103cca28097326814718e711c9c41b54853c26959d73495e40b1dd608f2 424B / 424B                                                                                                                                                      0.0s\n =&gt; =&gt; sha256:d1a528908992e9b5bcff8329a22de1749007d0eeeccb93ab85dd5a822b8d46a0 2.31kB / 2.31kB                                                                                                                                                  0.0s\n =&gt; =&gt; extracting sha256:064a9bb4736de1b2446f528e4eb37335378392cf9b95043d3e9970e253861702                                                                                                                                                       0.7s\n =&gt; [2/3] RUN apt update &amp;&amp; apt -y upgrade                                                                                                                                                                                                      3.9s\n =&gt; [3/3] RUN apt install -y wget                                                                                                                                                                                                               2.3s\n =&gt; exporting to image                                                                                                                                                                                                                          0.1s\n =&gt; =&gt; exporting layers                                                                                                                                                                                                                         0.1s\n =&gt; =&gt; writing image sha256:48bdb8036e8c97d6fde1e515291345425b78b3c33830768caad12ad98ea17b2c                                                                                                                                                    0.0s\n</code></pre> <p>Once the build process is finished, the output should be <code>Building ... FINISHED</code>. Then you are good to go.</p> <p>As next step, we will check with the command <code>docker images</code> that you see the newly built image in the list of images.</p> <p>Exercise</p> <pre><code>docker images\n</code></pre> Solution <p></p><pre><code>account@your-computer folder % docker images \nREPOSITORY                 TAG       IMAGE ID       CREATED         SIZE \nmytestimage                v1        48bdb8036e8c   7 minutes ago   96.9MB \n</code></pre> Let\u2019s check the ID of the image to run it later.  <p>But right now, we investigate some additional statements for the recipes!</p> <p>Additional statements for the Dockerfile    </p> command what does it do? Example LABEL Who is maintaining the container image LABEL  maintainer=\u201dyour name your.email@domain.org\u201d WORKDIR all subsequent actions will be executed in that working directory. WORKDIR ~ COPY lets you copy a local file or directory from your host (the machine from which you are building the image) COPY ~/.bashrc . # COPY source destination ADD same, but ADD works also for URLs, and for .tar archives that will be automatically extracted upon being copied. ARG available only while the image is built ENV available for the future running containers ENTRYPOINT The ENTRYPOINT specifies a command that will always be executed when the container starts. CMD The CMD specifies arguments that will be fed to the ENTRYPOINT. <p>Further readings</p> <p>Difference between ADD and COPY explained here and here.</p> <p>Difference between ARG and ENV explained here.</p>"},{"location":"chapters/chapter_02/#a-longer-recipe","title":"A longer recipe","text":"<p>Below is a longer recipe (save it in a text file named <code>Dockerfile-ex2</code>):</p> Dockerfile-ex2<pre><code>FROM ubuntu:18.04\n\nLABEL version=\"1.0\"\nLABEL description=\"This is an example image\\\nthat should download a picture once run.\"\n\nWORKDIR /scratch \n\nRUN apt-get update &amp;&amp; apt-get -y upgrade\nRUN apt-get install -y wget\n\nENTRYPOINT [\"/usr/bin/wget\"]\nCMD [\"https://cdn.wp.nginx.com/wp-content/uploads/2016/07/docker-swarm-hero2.png\"]\n</code></pre> <p>Exercise</p> <p>Let\u2019s also build a Docker image based on the <code>Dockerfile-ex2</code>. What is the syntax?</p> Solution <pre><code>account@your-computer folder % docker build -t download-image:v1 -f Dockerfile-ex2 .\n...\naccount@your-computer folder % docker images\nREPOSITORY                 TAG       IMAGE ID       CREATED         SIZE\ndownload-image             v1        42f09c5ca259   34 seconds ago   96.9MB\n</code></pre> <p>Tips for Docker files</p> <p>You should try to separate the Dockerfile into as many stages as possible, because this will allow for better caching.</p> <p>For example for <code>apt-get</code>:</p> <p>You must run apt-get update and apt-get install in the same command, otherwise you will encounter caching issues. Remember to use apt-get install -y, because you will have no control over the process while it\u2019s building.</p>"},{"location":"chapters/chapter_02/#running-our-docker-container","title":"Running our Docker container","text":"<p>Now we want to use what is inside the image.</p> <p><code>docker run</code> creates a fresh container (active instance of the image) from a Docker (static) image, and runs it.</p> <p>The format is:</p> <pre><code>docker run [docker options] &lt;IMAGE NAME&gt; [image arguments]\n</code></pre> <p>This means that arguments that affect the way Docker runs must always go before the image name, but arguments that are passed to the image itself must go after the image name.</p> <p>Exercise</p> <p>You can execute any program/command that is stored inside the image. What happens if you execute <code>ls</code> in your current working directory: is the result the same? </p><pre><code>docker run mytestimage:v1 /bin/ls\n</code></pre> Answer <p>No, it is not. The listing of the working directory within the container will be displayed. In our case, this is <code>/</code>.   </p> <p>Exercise</p> <p>You can execute any program/command that is stored inside the image.</p> <pre><code>docker run mytestimage:v1 /bin/whoami\ndocker run mytestimage:v1 cat /etc/issue\n</code></pre> Answer <p>Anything surprising happened and why? The first command did not produce a valid output. Which command do you have to run to get a valid response? And what is the user?   </p> <p>List running containers</p> <p>Let\u2019s run another command in the shell.</p> <pre><code>docker ps\n</code></pre> <p>In this case, we would like list all running containers but we will get back an empty result.</p> <pre><code>account@your-computer ~ % docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n</code></pre> <p>This is normal since before each of the executed containers only ran a very short time. All commands were executed in milliseconds.  </p> <p>Now, let\u2019s list all containers whether they are running or not:</p> <pre><code>docker ps -a\n</code></pre> <p>Now, the result is more insightful.</p> <pre><code>albot@Alexanders-MacBook-Pro ~ % docker ps -a\nCONTAINER ID   IMAGE               COMMAND                  CREATED          STATUS                      PORTS     NAMES\n6cdfeb6b412f   mytestimage:v1      \"whoami\"                 8 minutes ago    Exited (0) 5 minutes ago              determined_torvalds\ne7a143e1b594   mytestimage:v1      \"cat /etc/issue\"         9 minutes ago    Exited (0) 5 minutes ago              elated_lalande\n7fed0970b698   mytestimage:v1      \"/bin/whoami\"            10 minutes ago   Created                               frosty_noether\n</code></pre> <p>The IDs that are shown can be useful for other docker commands like <code>docker stop</code> and <code>docker exec</code> in case the containers will run longer. The containers with the IDs <code>6cdfeb6b412f</code> and <code>e7a143e1b594</code> have been run succesfully and now have the status <code>Excited</code>. The last one has only been created since we received an error message. We will not go into more details now. In a chapter later on, we will shortly touch on the containers which run e.g. web applications.</p> <p>But before we go on to second image we have created before, let\u2019s run an container interactively.</p> <pre><code>docker run -it mytestimage:v1\n</code></pre> <p>Exercise</p> <p>Verify what the operating system of the container is? One option is <code>cat /etc/os-release</code>. </p> Answer <pre><code>root@5a7f73d47ff5:/# cat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"18.04.6 LTS (Bionic Beaver)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 18.04.6 LTS\"\nVERSION_ID=\"18.04\"\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nVERSION_CODENAME=bionic\nUBUNTU_CODENAME=bionic\n</code></pre> <p>Exercise</p> <p>Run the command <code>whoami</code>, now in the container.</p> Answer <p>You might have seen before that you are indeed <code>root</code>. This also means that you can install other programms in this interactive shell. </p> <p>Before we exit the shell in the container, we will have a quick look at the status of the container like we did above.</p> <p>Exercise</p> <p>Please open another terminal and type <code>docker ps -a</code>. </p> Answer <p>You will see that the current container <code>5a7f73d47ff5</code> has the status <code>Up</code>. So, it is indeed still running since we have started an interactive shell.  </p><pre><code>CONTAINER ID   IMAGE               COMMAND                  CREATED             STATUS                         PORTS     NAMES\n5a7f73d47ff5   mytestimage:v1      \"/bin/bash\"              11 minutes ago      Up 11 minutes                            vigorous_taussig\n6cdfeb6b412f   mytestimage:v1      \"whoami\"                 57 minutes ago      Exited (0) 57 minutes ago                determined_torvalds\ne7a143e1b594   mytestimage:v1      \"cat /etc/issue\"         58 minutes ago      Exited (0) 58 minutes ago                elated_lalande\n7fed0970b698   mytestimage:v1      \"/bin/whoami\"            58 minutes ago      Created                                  frosty_noether\n</code></pre> <p>Exit the interactive container by typing <code>exit</code> so that we return to the shell of our host. Let\u2019s come back to our second image we have created before.</p> <p>First identify the id of this image by running <code>docker images</code>. When preparing the course, the ID was <code>42f09c5ca259</code>.</p> <p>Exercise</p> <p>Run this container without any specific command. You might recall that a default command is defined in the recipe.</p> Answer <pre><code>account@your-computer folder % docker run 42f09c5ca259\n--2023-12-30 13:59:48--  https://cdn.wp.nginx.com/wp-content/uploads/2016/07/docker-swarm-hero2.png\nResolving cdn.wp.nginx.com (cdn.wp.nginx.com)... 104.18.10.5, 104.18.11.5\nConnecting to cdn.wp.nginx.com (cdn.wp.nginx.com)|104.18.10.5|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 446827 (436K) [image/png]\nSaving to: 'docker-swarm-hero2.png'\n\n  0K .......... .......... .......... .......... .......... 11% 13.0M 0s\n 50K .......... .......... .......... .......... .......... 22% 12.1M 0s\n100K .......... .......... .......... .......... .......... 34% 5.30M 0s\n150K .......... .......... .......... .......... .......... 45% 6.02M 0s\n200K .......... .......... .......... .......... .......... 57% 10.4M 0s\n250K .......... .......... .......... .......... .......... 68% 9.34M 0s\n300K .......... .......... .......... .......... .......... 80% 11.0M 0s\n350K .......... .......... .......... .......... .......... 91% 2.73M 0s\n400K .......... .......... .......... ......               100%  250M=0.06s\n\n2023-12-30 13:59:48 (7.41 MB/s) - 'docker-swarm-hero2.png' saved [446827/446827]\n</code></pre> <p>As you see, the png file is downloaded but do you find it on the host? Probably no since the container is isolated from the host.</p>"},{"location":"chapters/chapter_02/#volumes","title":"Volumes","text":"<p>Docker containers are fully isolated. It is necessary to mount volumes in order to handle input/output files. By default, Docker containers cannot access data on the host system. This means you cannot use host data in your containers. All data stored in the container will be lost when the container exits.</p> <p>You can solve this like this:</p> <p>-v /path/in/host:/path/in/container: This bind mounts a host file or directory into the container. Writes to one will affect the other. Note that both paths have to be absolute paths, so you often want to use<code>pwd</code>/some/path</p> <p>Exercise</p> <p>For this exercise, we will bind-mount the current directory of our user on the host machine to the <code>WORKDIR</code> as defined in the Dockerfile-ex2. <code>docker run --volume $(pwd):/scratch download-image:v1</code></p> Answer <pre><code>--2023-12-30 16:55:20--  https://cdn.wp.nginx.com/wp-content/uploads/2016/07/docker-swarm-hero2.png\nResolving cdn.wp.nginx.com (cdn.wp.nginx.com)... 104.18.10.5, 104.18.11.5\nConnecting to cdn.wp.nginx.com (cdn.wp.nginx.com)|104.18.10.5|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 446827 (436K) [image/png]\nSaving to: 'docker-swarm-hero2.png'\n\n  0K .......... .......... .......... .......... .......... 11% 13.0M 0s\n 50K .......... .......... .......... .......... .......... 22% 12.1M 0s\n100K .......... .......... .......... .......... .......... 34% 5.30M 0s\n150K .......... .......... .......... .......... .......... 45% 6.02M 0s\n200K .......... .......... .......... .......... .......... 57% 10.4M 0s\n250K .......... .......... .......... .......... .......... 68% 9.34M 0s\n300K .......... .......... .......... .......... .......... 80% 11.0M 0s\n350K .......... .......... .......... .......... .......... 91% 2.73M 0s\n400K .......... .......... .......... ......               100%  250M=0.06s\n\n2023-12-30 16:55:21 (7.41 MB/s) - 'docker-swarm-hero2.png' saved [446827/446827]\n</code></pre> <p>As you see, the png file is downloaded and do you find it on the host in the current working directory?  If all went fine, you should see the file <code>docker-swarm-hero2.png</code> in your current directory.</p>"},{"location":"chapters/chapter_02/#22-container-registries-eg-docker-hub","title":"2.2 Container registries (e.g. Docker Hub)","text":"<p>Images can be stored locally or shared in a registry. Docker hub is the main public registry for Docker images. Let\u2019s search the keyword \u201cubuntu\u201d</p> <p>Exercise</p> <pre><code>docker pull ubuntu\n</code></pre> Answer <pre><code>debian@debian:~$ docker search ubuntu\nNAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED    \nubuntu                           Ubuntu is a Debian-based Linux operating sys\u2026   16831     [OK]       \nwebsphere-liberty                WebSphere Liberty multi-architecture images \u2026   296       [OK]       \nubuntu-upstart                   DEPRECATED, as is Upstart (find other proces\u2026   115       [OK]       \nubuntu/nginx                     Nginx, a high-performance reverse proxy &amp; we\u2026   111                  \nneurodebian                      NeuroDebian provides neuroscience research s\u2026   106       [OK]       \nubuntu/squid                     Squid is a caching proxy for the Web. Long-t\u2026   76                   \nubuntu/apache2                   Apache, a secure &amp; extensible open-source HT\u2026   70                   \nubuntu/bind9                     BIND 9 is a very flexible, full-featured DNS\u2026   69                   \nopen-liberty                     Open Liberty multi-architecture images based\u2026   62        [OK]       \nubuntu/mysql                     MySQL open source fast, stable, multi-thread\u2026   58                   \nubuntu/prometheus                Prometheus is a systems and service monitori\u2026   55                   \nubuntu-debootstrap               DEPRECATED; use \"ubuntu\" instead                52        [OK]       \nubuntu/kafka                     Apache Kafka, a distributed event streaming \u2026   38                   \nubuntu/postgres                  PostgreSQL is an open source object-relation\u2026   34                   \nubuntu/redis                     Redis, an open source key-value store. Long-\u2026   22                   \nubuntu/dotnet-aspnet             Chiselled Ubuntu runtime image for ASP.NET a\u2026   17                   \nubuntu/dotnet-runtime            Chiselled Ubuntu runtime image for .NET apps\u2026   14                   \nubuntu/jre                       Distroless Java runtime based on Ubuntu. Lon\u2026   13                   \nubuntu/dotnet-deps               Chiselled Ubuntu for self-contained .NET &amp; A\u2026   13                   \nubuntu/zookeeper                 ZooKeeper maintains configuration informatio\u2026   12                   \nubuntu/grafana                   Grafana, a feature rich metrics dashboard &amp; \u2026   9                    \nubuntu/prometheus-alertmanager   Alertmanager handles client alerts from Prom\u2026   9                    \nubuntu/memcached                 Memcached, in-memory keyvalue store for smal\u2026   5                    \nubuntu/cortex                    Cortex provides storage for Prometheus. Long\u2026   4                    \nubuntu/cassandra                 Cassandra, an open source NoSQL distributed \u2026   2                    \ndebian@debian:~$ \n</code></pre> <p>There are a lot of alternatives to Docker hub for image registries depending on the needs of the organisation or company. Some examples are shown below:</p> Logo Name Quay.io Amazon ECR Github CR <ol> <li>Get the latest image or latest release</li> </ol> <p>In this case, the Ubuntu image with the tag <code>latest</code> is downloaded.</p> <pre><code>albot@Alexanders-MacBook-Pro toto % docker pull ubuntu\nUsing default tag: latest\nlatest: Pulling from library/ubuntu\n005e2837585d: Pull complete\nDigest: sha256:6042500cf4b44023ea1894effe7890666b0c5c7871ed83a97c36c76ae560bb9b\nStatus: Downloaded newer image for ubuntu:latest\ndocker.io/library/ubuntu:latest\n</code></pre> <ol> <li>Check the versions of Ubuntu present and fetch version 18.04 using tags</li> </ol> <pre><code>debian@debian:~$ docker pull ubuntu:18.04\n18.04: Pulling from library/ubuntu\n064a9bb4736d: Pull complete \nDigest: sha256:152dc042452c496007f07ca9127571cb9c29697f42acbfad72324b2bb2e43c98\nStatus: Downloaded newer image for ubuntu:18.04\ndocker.io/library/ubuntu:18.04\ndebian@debian:~$ \n</code></pre> <p>When you ran this command, Docker first looked for the image on your local machine, and when it couldn\u2019t find it, pulled it down from a cloud registry of Docker images called Docker Hub.</p> <p>What other repositories are possible? Have a look at the web site https://biocontainers.pro/ which is a specific directory of Bioinformatics related tools. the images are stored in Docker hub and/or Quay.io (RedHat registry) these images are normally created from Bioconda</p> <p>Example: FastQC https://biocontainers.pro/#/tools/fastqc</p> <pre><code>debian@debian:~$ sudo docker pull biocontainers/fastqc:v0.11.9_cv7\nv0.11.9_cv7: Pulling from biocontainers/fastqc\n9ff7e2e5f967: Pull complete \n59856638ac9f: Pull complete \n6f317d6d954b: Pull complete \na9dde5e2a643: Pull complete \n675cac559d07: Pull complete \n0e6dd20ee818: Pull complete \n374c558e71da: Pull complete \n0df3c64bb19a: Pull complete \ne936d7784cf9: Pull complete \n4dfd8d164cc5: Pull complete \n473490461998: Pull complete \n8f5e491552e6: Pull complete \na66ab3a674d9: Pull complete \n18f922275a6f: Pull complete \n6d0254e75eec: Pull complete \nDigest: sha256:8ff2a75c6864edec10c92b3a085cc2f3b207107363c83772feab711d13022c3d\nStatus: Downloaded newer image for biocontainers/fastqc:v0.11.9_cv7\ndocker.io/biocontainers/fastqc:v0.11.9_cv7\ndebian@debian:~$\n</code></pre> <p>Where are these images stored? On Linux, they usually go to /var/lib/. Docker is very greedy in storage, so regular cleaning is necessary. We will see later on how you can do the purging. Sometimes, it is also useful to get more information about the images. You can do this via</p> <pre><code>docker image inspect\n</code></pre> <p>And lastly to complete the Docker Dance, we shortly show how to upload own containers to the DockerHub registry.</p> <p>Note: You will have to use a public repository on DockerHub.</p> <p>First, you will have to create an account on DockerHub. </p> <p>Usually, as first step before the upload of the image to the registry, you will use <code>docker login</code>. In this case, the command assumes that you\u2019d like to login to DockerHub. </p> <p>As you have seen before, we have created two images based on simple recipes. Imagine that you\u2019d like to share them publically. You will use the command <code>docker push</code>. But before you need to rename the docker image so that the <code>push</code> command knows where the destination is.</p> <pre><code>docker tag download-image:v1 yourhubusername/download-image:v1\ndocker push yourhubusername/download-image:v1\n</code></pre> <p>Useful resources</p> <p>Dockerfile reference Best practices for manual creation Ten simple rules for writing Dockerfiles for reproducible data science </p>"},{"location":"chapters/chapter_03/","title":"3. To Boldly Dock (Learning more about containers)","text":""},{"location":"chapters/chapter_03/#to-boldly-dock","title":"To Boldly Dock....","text":""},{"location":"chapters/chapter_03/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Have an understanding of the challenges of building an efficient Docker container on your computer.</li> <li>Be aware of resources on techniques and best practices to address these chjallenges</li> </ul>"},{"location":"chapters/chapter_03/#31-where-to-go-next-in-developing-your-docker-skills","title":"3.1 Where to go next in developing your Docker skills","text":"<p>Our course could only cover the basics of creating and using containers in Docker. This section is intended to suggest options that you may find useful and where to get more information on them.    </p>"},{"location":"chapters/chapter_03/#32-shrinking-containers","title":"3.2 Shrinking containers","text":"<p>As we put more functionality into our containers (and more layers in our Dockerfiles) they can get large (though they will still be smaller than VMs and can share common layers between different containers if we are running more than one container on a host).  Big containers take longer to download and spin up and consume more resources on repositories and target hosts.   </p> <p>How do we get around/avoid this? </p>"},{"location":"chapters/chapter_03/#321-clever-dockerfile-tricks","title":"3.2.1 Clever Dockerfile tricks","text":"<p>We can combine statements from layers into 1 layer using &amp;&amp;   We can clean up temporary files e.g. if there is a build from source step we can use &amp;&amp; ro have steps to delete the temporary and source files leaving only the executable and this will make that layer smaller when it is finalised into the container.  An example of this: </p><pre><code>USER root\nADD copy_course.sh /scripts/copy_course.sh\nRUN chmod +x /scripts/copy_course.sh \n# need fastqc, samtools bwa bowtie picard-tools GATK jre wget git\nRUN apt-get update &amp;&amp; apt-get -y install bowtie bwa curl default-jre fastqc git gzip monit \\\n    picard-tools poppler-utils samtools sudo wget\nRUN  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \n#fix fastqc\nRUN mkdir /etc/fastqc &amp;&amp; mkdir /etc/fastqc/Configuration\nADD fastqc/* /etc/fastqc/Configuration/\n\nRUN mkdir $DOCS &amp;&amp; mkdir $DATA &amp;&amp;  mkdir $WORK &amp;&amp; mkdir /coursehome\n</code></pre> <p>What are the issues with this approach?  Dockerfile Readability - these \u2018tricks\u2019 can make it hard for the reader to understand  what the Dockerfile is doing. This can severly impact on Reproducibility &amp; Resuabilirt (Last letter of FAIR principles).    Harder to debug any Syntax errors during build step. If the build breaks - which part of  the line caused it to fail? How would you go about detrmining the cause?    </p>"},{"location":"chapters/chapter_03/#322-using-a-different-linux-distribution-eg-alpine","title":"3.2.2 Using a different linux distribution e.g. Alpine","text":"<p>There are \u201cSlimline\u201d distributions like Alpine linux. These originate from the world of embedded devices e.g. routers and data-loggers where storage space is at a premium and so are ideal for building small linux appliances. A base Alpine linux distribution is only 4 megabytes in size. Tiny, when compared to the Gigabytes of a typical linux distribution! * Downside - come with their own package managers (i.e. apk not apt or yum) and so you will have to rewrite your installation recipes to use apk in the Dockerfile. Also packages max not exist for certain software tools neccessitating compiling from source code (i.e. linux expertise required). Some example Bioinformatics Docker containers built on Alpine are at https://hub.docker.com/u/bioslimcontainers .       </p>"},{"location":"chapters/chapter_03/#323-multi-stage-builds","title":"3.2.3 Multi-stage builds","text":"<p>An update in newer versions of Docker, this process allows us to have a Dockerfile that has two images associated with it. One is a build stage where software is built and installed then the destination stage (which is what the end user will use) is an compact empty OS image that has just the built software copied to it leaving behind all the (space occupying) detritus of the build process.   See here for the Docker documentation on this.  It\u2019s probably the best way to go for readable, compact containers.    </p>"},{"location":"chapters/chapter_03/#33-publishing-containers","title":"3.3 Publishing containers","text":"<p>In our course we used the Dockerhub repository but there are other choices:  Quay,io Github Container registry  * Many others free &amp; commercial: AWS, Azure, Google, Gitlab, Harbor &amp; Artifactory {See here](https://octopus.com/blog/top-8-container-registries)   The upside is that the commands for connecting to the registry in order to push container to it are basically the same regardless of which repository you use (Though obviously you should read the relevant documentation). An example of using the docker command line to push a container to GH Container registry is here.</p> <p>Why use anything else?  Good question : politics &amp; cost are faactors. For a long time Docker had a generous free tier ideal for learners and open source developers but they are now cutting back with an aim to monetise the Hub registry. Others have stepped in to try and take a share in the Market. Red Hats quay was an early contender but as stated above more have come to market especially the Cloud Computing service providers as they can run more Docker containers than VMs for the same server resources.  </p> <p>More repositories are good for our reproducibilty agenda - we can host our containers on multiple services and be more resilient to service outages or vendors going out of business. * A lot of the providers have supplied Github Actions (Which are effectively scripts that run Githubs servers) to automate container builds from a github code repository and storing the finished container in their container registry. Providing a Continuous Integration/Continuous Delivery (CI/CD) route to maintaing your software.   See here for an article on  this for Githubs registry.   * For publications you can use Zenodo to create a DOI pointing to your containers.    </p>"},{"location":"chapters/chapter_03/#34-other-ways-to-run-containers","title":"3.4 Other ways to run containers","text":"<p>Docker is unpopular with adminstrators of High Performance Computing (Clusters) as it is possible for a container to run with root (i.e. super user/administrator) privileges.  If you wish to run your containers in these environments, here are a couple of options;  1. Apptainer (The software formerly known as Singularity) https://apptainer.org 2. Podman https://podman-desktop.io</p>"},{"location":"chapters/chapter_03/#next-chapter-applying-our-new-container-skills-to-a-real-python-script","title":"Next chapter: Applying our new Container skills to a real Python script","text":"<p>In our next and final section we will take the Elixir Reproducibility workflow and build it into a supportive container.      </p>"},{"location":"chapters/chapter_04/","title":"4. To Tie it together and run the Python script","text":""},{"location":"chapters/chapter_04/#learning-outcomes","title":"Learning outcomes","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>run the Python script using a Docker container on your computer.</li> <li>run the Python script using a Juptyer Notebook container on your computer.</li> </ul> <p>We will be using the Elixir CodeRep example workflow (Python version) which can be found here. It is a simplified Machine Learning workflow that attempts to classifty  tumours as benign or malignant based upon characteristics in the data.    More details on the scripts can be found on the afore-mentioned CodeRep Github repository.   </p> <p>As is often the case in Computing problems, when it comes to executing the workflow there are more than one single approach to  achieving the goal. We present a few here:   </p>"},{"location":"chapters/chapter_04/#41-running-the-script-within-a-jupyter-notebook-via-docker-desktop","title":"4.1 Running the script within a Jupyter Notebook (via Docker Desktop)","text":"<p>We will use Docker to start a JupyterNotebook within the JupyterLabs environment.</p> <p>Working with JupyterLabs as a Docker extension begins with opening the Docker Desktop. </p> <p>Here are the steps to follow:</p> <ul> <li>Choose Extensions in the left sidebar.</li> <li>Switch to the Browse tab.</li> <li>In the Categories drop-down, select Utility Tools.</li> <li>Find Jupyter Notebook and then select Install.</li> </ul> <p>Wait a bit before the JupyterLabs extension is installed. You can start the extension by the JupyterNotebook icon on the left side of the Docker Desktop menu.</p> <p>Open a Terminal by clicking the Terminal icon under the Other category. Clone the directory by using <code>git clone</code>. </p><pre><code>git clone https://github.com/elixir-europe-training/ELIXIR-TrP-ContainersPython-CodeRep.git\n</code></pre> <p>Open the Jupyter notebook in the <code>examples</code> directory of the said repository. You should be able to execute the Python code using the notebook.</p> <p>In case, you like to extract the output from the notebook, you could run the following docker command. Obviously, you could also download the content via the interface.</p> <pre><code>docker run --rm --volumes-from jupyter_embedded_dd_vm -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /home/jovyan/work\n</code></pre>"},{"location":"chapters/chapter_04/#42-running-the-python-script-on-the-command-line-2-examples","title":"4.2 Running the Python script on the command line (2 examples)","text":"<p>In order to run the script using a Docker container, we will use the same Docker image which is used for running the JupyterLab in the example above.</p> <p>Exercise</p> <pre><code>docker images\ndocker image inspect jupyter/scipy-notebook:lab-4.0.6 | grep Working\n</code></pre> <p>Furthermore, please clone the above repo again on your local computer. Switch to the examples directory.</p> <p>In order to run the script, we need to bind mount the local directory where the script and two python files are. Furthermore, we need to specify a working directory upon running the container (and we also need to specify a user and group ID for Linux hosts).</p> <p></p><pre><code>cd examples/\ndocker run --rm -v $(pwd):/home/jovyan/work/ -w /home/jovyan jupyter/scipy-notebook:lab-4.0.6 python codereppy_min_batch.py\n</code></pre> Another way of running things on the command line  We will use a pre-built Docker image produced by the Jupyter project and will pull it from a quay.io registry (Jupyter appear to be moving away from Docker hub). Futher details on this image and parameters to tailor behaviour when run can be found here.      The raw Dockerfile used to construct this container is inspectable on Github.   NB We could take things further and use this as a source layer in our own dockerfile with the script and data to create a dedicated single purpose container (A topic for an advanced course).     <pre><code>docker run -it --rm -p 10000:8888 -v \"${PWD}\":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-15\n\n http://127.0.0.1:8888/lab?token=b71632b47d40d57e1173d211d1972c261b70b3bc4d503f50\n[I 2024-02-05 16:14:51.455 ServerApp] Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\nc[I 2024-02-05 16:22:21.248 LabApp] 302 GET /lab?token=[secret] (@172.17.0.1) 1.28ms\n[I 2024-02-05 16:24:56.112 ServerApp] User f99ecbe86c6f4e8aa45a21dd895ac41f logged in.\n[I 2024-02-05 16:24:56.113 ServerApp] 302 POST /login?next=%2F (f99ecbe86c6f4e8aa45a21dd895ac41f@172.17.0.1) 2.04ms\n[I 2024-02-05 16:24:56.116 ServerApp] 302 GET / (@172.17.0.1) 0.29ms\n0.00s - Debugger warning: It seems that frozen modules are being used, which may\n0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n0.00s - to python to disable frozen modules.\n</code></pre> <p>Open byour web rowser to the URL displayed in terminal. At the login screen use the token (displayed after token= line in terminal)   . You will then be in a Jupyter Notebook. As in previous examples navigate to the \u2018Other\u2019 screen and activate Terminal.         Example Terminal output after git cloning workflow </p><pre><code>(base) jovyan@c481ec0bb643:~$ git clone https://github.com/elixir-europe-training/ELIXIR-TrP-ContainersPython-CodeRep.git\nCloning into 'ELIXIR-TrP-ContainersPython-CodeRep'...\nremote: Enumerating objects: 745, done.\nremote: Counting objects: 100% (202/202), done.\nremote: Compressing objects: 100% (135/135), done.\nremote: Total 745 (delta 137), reused 80 (delta 58), pack-reused 543\nReceiving objects: 100% (745/745), 12.71 MiB | 837.00 KiB/s, done.\nResolving deltas: 100% (397/397), done.\n(base) jovyan@c481ec0bb643:~$\n</code></pre> <p> </p> <p>You can now load and run the python file and see the graphs in the Notebook pane.    </p> <p>When you have finished with docker you can clear the downloaded Docker images with: </p><pre><code>docker system prune -a\n</code></pre> More information about cleaning up Docker iamages here <p>Discussionn exercise - how do these approaches differ? Why would we use one over another?</p> answer <p>They produce different outputs and require different levels of command line skills. Which would you choose?      </p> <p>Congratulations! You have reached the end of this course.  We hope that you have learned about this aspect of Reproducible Research and will be able to apply it to your own endeavours!   The Elixir CodeRep Containers team </p>"},{"location":"chapters/references/","title":"References","text":""},{"location":"chapters/references/#references","title":"References","text":"<ul> <li>Virtual Machines &amp; virtualisation </li> <li>The Dockerfile Reference </li> <li>Docker Multi-stage builds </li> </ul> <ol> <li> <p>Nancy J Hoebelheinrich, Katarzyna Biernacka, Michelle Brazas, Leyla Jael Castro, Nicola Fiore, Margareta Hellstrom, Emma Lazzeri, Ellen Leenarts, Paula Maria Martinez Lavanchy, Elizabeth Newbold, Amy Nurnberger, Esther Plomp, Lucia Vaira, Celia W G van Gelder, and Angus Whyte. Recommendations for a minimal metadata set to aid harmonised discovery of learning resources. June 2022. URL: https://doi.org/10.15497/RDA00073, doi:10.15497/RDA00073.\u00a0\u21a9</p> </li> <li> <p>Leyla Garcia, B\u00e9r\u00e9nice Batut, Melissa L. Burke, Mateusz Kuzak, Fotis Psomopoulos, Ricardo Arcila, Teresa K. Attwood, Niall Beard, Denise Carvalho-Silva, Alexandros C. Dimopoulos, Victoria Dominguez Del Angel, Michel Dumontier, Kim T. Gurwitz, Roland Krause, Peter McQuilton, Loredana Le Pera, Sarah L. Morgan, P\u00e4ivi Rauste, Allegra Via, Pascal Kahlem, Gabriella Rustici, Celia W.G. Van Gelder, and Patricia M. Palagi. Ten simple rules for making training materials FAIR. PLoS Computational Biology, 16(5):1\u20139, 2020. doi:10.1371/journal.pcbi.1007854.\u00a0\u21a9</p> </li> <li> <p>When we share, everyone wins. Accessed: 2022-08-11. URL: https://creativecommons.org/.\u00a0\u21a9</p> </li> <li> <p>Open source licenses: types and comparison. Accessed: 2023-02-10. URL: https://snyk.io/learn/open-source-licenses/.\u00a0\u21a9</p> </li> <li> <p>Jon Ison, Mat\u00fa\u0161 Kala\u0161, Inge Jonassen, Dan Bolser, Mahmut Uludag, Hamish McWilliam, James Malone, Rodrigo Lopez, Steve Pettifer, and Peter Rice. EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats. Bioinformatics, 29(10):1325\u20131332, 03 2013. URL: https://doi.org/10.1093/bioinformatics/btt113, arXiv:https://academic.oup.com/bioinformatics/article-pdf/29/10/1325/710075/btt113.pdf, doi:10.1093/bioinformatics/btt113.\u00a0\u21a9</p> </li> </ol>"},{"location":"keywords/","title":"Keywords","text":"<p>Here\u2019s a lit of used keywords:</p> <ol> <li> <p>Nancy J Hoebelheinrich, Katarzyna Biernacka, Michelle Brazas, Leyla Jael Castro, Nicola Fiore, Margareta Hellstrom, Emma Lazzeri, Ellen Leenarts, Paula Maria Martinez Lavanchy, Elizabeth Newbold, Amy Nurnberger, Esther Plomp, Lucia Vaira, Celia W G van Gelder, and Angus Whyte. Recommendations for a minimal metadata set to aid harmonised discovery of learning resources. June 2022. URL: https://doi.org/10.15497/RDA00073, doi:10.15497/RDA00073.\u00a0\u21a9</p> </li> <li> <p>Leyla Garcia, B\u00e9r\u00e9nice Batut, Melissa L. Burke, Mateusz Kuzak, Fotis Psomopoulos, Ricardo Arcila, Teresa K. Attwood, Niall Beard, Denise Carvalho-Silva, Alexandros C. Dimopoulos, Victoria Dominguez Del Angel, Michel Dumontier, Kim T. Gurwitz, Roland Krause, Peter McQuilton, Loredana Le Pera, Sarah L. Morgan, P\u00e4ivi Rauste, Allegra Via, Pascal Kahlem, Gabriella Rustici, Celia W.G. Van Gelder, and Patricia M. Palagi. Ten simple rules for making training materials FAIR. PLoS Computational Biology, 16(5):1\u20139, 2020. doi:10.1371/journal.pcbi.1007854.\u00a0\u21a9</p> </li> <li> <p>When we share, everyone wins. Accessed: 2022-08-11. URL: https://creativecommons.org/.\u00a0\u21a9</p> </li> <li> <p>Open source licenses: types and comparison. Accessed: 2023-02-10. URL: https://snyk.io/learn/open-source-licenses/.\u00a0\u21a9</p> </li> <li> <p>Jon Ison, Mat\u00fa\u0161 Kala\u0161, Inge Jonassen, Dan Bolser, Mahmut Uludag, Hamish McWilliam, James Malone, Rodrigo Lopez, Steve Pettifer, and Peter Rice. EDAM: an ontology of bioinformatics operations, types of data and identifiers, topics and formats. Bioinformatics, 29(10):1325\u20131332, 03 2013. URL: https://doi.org/10.1093/bioinformatics/btt113, arXiv:https://academic.oup.com/bioinformatics/article-pdf/29/10/1325/710075/btt113.pdf, doi:10.1093/bioinformatics/btt113.mkdocs\u00a0\u21a9</p> </li> </ol>"}]}